{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fGduYVZGlaml"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElCald/CIFAR10/blob/main/TP2/2-how_to_use_lstm_for_one_to_many_many_to_one_and_many_to_many_sequences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemples simples de LSTM pour des séquences"
      ],
      "metadata": {
        "id": "XVBx-edtm4di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Setups"
      ],
      "metadata": {
        "id": "79soaii8iRvz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylFg6ScZhtsC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rnS8RPAhiYr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Séquence *One to Many*"
      ],
      "metadata": {
        "id": "1rh5St_dmvN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Génération des données"
      ],
      "metadata": {
        "id": "SGjmB-nFjpqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = [], []\n",
        "X = [x+3 for x in range(-2, 43, 3)]\n",
        "\n",
        "for i in X:\n",
        "    output_vector = []\n",
        "    output_vector.append(i+1)\n",
        "    output_vector.append(i+2)\n",
        "    Y.append(output_vector)\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "YlFW50w5iuZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reformater l'entrée pour avoir la forme `[batch, timesteps, feature]`."
      ],
      "metadata": {
        "id": "VMq6ncUvjZ0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X).reshape(15, 1, 1)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(f\"Shape of X: {X.shape} and shape of Y: {Y.shape}\")"
      ],
      "metadata": {
        "id": "kBILu-HLizUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Créer un modèle"
      ],
      "metadata": {
        "id": "H9Vi3jacjrWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    inputs = layers.Input(shape=(1,1))\n",
        "    lstm = layers.LSTM(50, activation=\"relu\")(inputs)\n",
        "    outputs = layers.Dense(2)(lstm)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uCs4l_3yizSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "fGduYVZGlaml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=50, validation_split=0.2, batch_size=3)\n"
      ],
      "metadata": {
        "id": "RdwnWkHuizQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##History"
      ],
      "metadata": {
        "id": "ey4sHvkRBnXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zrrUELaXBj26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prédiction\n",
        "\n",
        "ici on passe la valeur 10. Le résultat devrait être un array [11, 12], ou plutôt quelque chose de proche ;)"
      ],
      "metadata": {
        "id": "aB3njgNqmR93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array([10]) # on s'attend à [11, 12] en sortie\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input)\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "TEircyJ0ltxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Est-ce qu'on peut faire mieux avec deux LSTM (Stacked LSTM) ?\n",
        "\n",
        "Comme dans le cas des FCN et CNN, l'ajout d'une couche supplémentaire peut parfois augmenter la précision des résultats."
      ],
      "metadata": {
        "id": "NYQHf7QADtUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    inputs = layers.Input(shape=(1,1))\n",
        "    lstm1 = layers.LSTM(50, activation=\"relu\",return_sequences=True)(inputs)\n",
        "    lstm2 = layers.LSTM(25, activation=\"relu\")(lstm1)\n",
        "    outputs = layers.Dense(2)(lstm2)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Qy6j14HtD2IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "tuw8Y8XVEh4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=200, validation_split=0.2, verbose=1)\n"
      ],
      "metadata": {
        "id": "DsbG5H5pEh4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##History"
      ],
      "metadata": {
        "id": "h7Yw6Mj6Eh4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nteNv9ozEh4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "qhMNWHqeEh4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array([10]) # on s'attend à [11, 12] en sortie\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input)\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "Du6V6Eo5Eh4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Bidirectionnel\n",
        "\n",
        "Dans le fonctionnement \"courant\" d'un RNN (LSTM, GRU), la dépendance des données se fait dans un seul sens *chronologique*. Cependant, certaines données ont des dépendances dans les deux directions, alors on peut faire usage d'un LSTM Bidirectionnel. Dans notre exemple présenté ici,"
      ],
      "metadata": {
        "id": "a1wAaBhTsNcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Bidirectional(layers.LSTM(50, activation='relu'), input_shape=(1, 1)))\n",
        "model.add(layers.Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n"
      ],
      "metadata": {
        "id": "tCQuUBzdTfwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##History"
      ],
      "metadata": {
        "id": "nrReE41Ttyup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZkdnMXxDtyuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "N8miB439t2b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array([10]) # on s'attend à [11, 12] en sortie\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input)\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "6ZULeyYJt2b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, toujours pas de [11, 12]... Mais avec un loss d'environ 2, il faudra s'attendre à une variation importante.\n",
        "\n",
        "Dans ce cas, il faut essayer plus d'epochs et aussi de sauvegarder le meilleur modèle"
      ],
      "metadata": {
        "id": "bPL5CG2093ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many to One Sequence\n",
        "\n",
        "Après le \"One to many\", maintenant on fait une séquence Many-to-One. Un exemple d'usage réel serait celui d'une prévision de la température à partir de l'humidité et de la pression atmosphérique. Dans l'exemple simple ci-dessous, on fait des séquences [1,2,3] et on essayer de prédire la somme [6]."
      ],
      "metadata": {
        "id": "7XPu29qcnGyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "g3yHigjpnwlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([x+1 for x in range(45)])\n",
        "X = X.reshape(15,3,1)\n",
        "\n",
        "Y = []\n",
        "for x in X:\n",
        "    Y.append(x.sum())\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "8Cq40Enam1Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "qS1U7Y5WoDpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    inputs = layers.Input(shape=(3,1))\n",
        "    lstm = layers.LSTM(50, activation=\"relu\")(inputs)\n",
        "    outputs = layers.Dense(1)(lstm)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6YMVvu1sm1Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "9MAIkcxkpvlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=200, validation_split=0.2, verbose=0)\n"
      ],
      "metadata": {
        "id": "GvUujlDKm1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##History"
      ],
      "metadata": {
        "id": "HQseDTs8Cl2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5CQucOQrCl2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "pvWv6YKGptfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array([50,51,52]) ## on veut quelque chose proche de 153 en sortie (la somme des entrées)\n",
        "test_input = test_input.reshape((1, 3, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "yrdZBm5Jm1Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice :\n",
        "Essayez d'implémenter ce modèle en Pytorch.\n",
        "* utiliser Dataset et Dataloader\n",
        "* utiliser nn.LSTM\n",
        "\n",
        "Quelles sont les similarités et différences que vous trouvez ? Pour un même nombre d'epochs, quelle implémentation (keras-tf ou pytorch) semble plus précise ?\n",
        "\n",
        "**Déposer votre code python** (fichier .py avec l'ensemble de l'implémentation Pytorch) sur Moodle."
      ],
      "metadata": {
        "id": "PIlweAJmvOQA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FyzPB6g8H007"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BRhLXJ_u3OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many to Many Sequence\n",
        "\n",
        "Enfin, on peut faire du Many to Many, comme par exemple prédire la température des trois prochains jours à partir des trois derniers jours. Dans cet exemple, on a 3 valeurs [5, 10, 15] et on essaye de prédire la suite [20, 25, 30]."
      ],
      "metadata": {
        "id": "rqmG-llcp3Ui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "NpD7myH7xnc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = list()\n",
        "Y = list()\n",
        "X = [x for x in range(5, 301, 5)]\n",
        "Y = [y for y in range(20, 316, 5)]\n",
        "\n",
        "X = np.array(X).reshape(20, 3, 1)\n",
        "Y = np.array(Y).reshape(20, 3, 1)\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "O46R4ttMmWeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "Dans ce modèle, on reçoit 3 entrées et on veut créer 3 sorties. Comme LSTM produit une seule sortie, nous allons *multiplier* les sorties en récupérant les étapes intermédiaures (`return_sequences = True`).\n",
        "\n",
        "**Attention :** ceci ne marche car on a 3 features en entrée et 3 en sortie. Si le nombre ne correspond pas, il faudra adapter les tensors."
      ],
      "metadata": {
        "id": "qBT3fNa5p-q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    inputs = layers.Input(shape=(3, 1))  # sequence length 3, 1 feature\n",
        "    lstm_out = layers.LSTM(100, activation='relu', return_sequences=True)(inputs)\n",
        "    outputs = layers.Dense(1)(lstm_out)  # Dense applies to last dimension\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Y6UNQbYip9mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "FF1vJmHYxo50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=200, validation_split=0.2, verbose=0, batch_size=3)\n"
      ],
      "metadata": {
        "id": "efVLk0fyu2L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##History"
      ],
      "metadata": {
        "id": "5Blh5RUKDPAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eniS31IpDPAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "j3wPQXLWxqH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array([300, 305, 310]) # on s'atten à avoir quelque chose comme [315, 320, 325] en sortie\n",
        "test_input = test_input.reshape((1, 3, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "lovky1ZMviH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vi-c4Mtn8Bvd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}